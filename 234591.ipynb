{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E7icgipGOv2q"
      },
      "outputs": [],
      "source": [
        "#IMPORT MODULE\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional \n",
        "import torch\n",
        "from torchvision import transforms, models\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import FashionMNIST\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.init as init\n",
        "from tqdm import notebook\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "516eIe0bvuPU"
      },
      "outputs": [],
      "source": [
        "\n",
        "#HYPERPARAMETERS\n",
        "#setting all the hyperparameters to their initial values and creating lists of different hyperparmeter values that can be looped through when testing\n",
        "\n",
        "batch_size = 64\n",
        "batch_sizes = [64,128,256,512]\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "transformations = [\n",
        "    #basic normalization transformation\n",
        "    transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ]),\n",
        "    #random horizontal flip transformation\n",
        "    transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ]),\n",
        "    # colour jitter transformation\n",
        "    transforms.Compose([\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ]),\n",
        "    #random rotation transformation\n",
        "    transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "]\n",
        "\n",
        "learning_rates = [0.0001,0.001,0.01,0.1]\n",
        "\n",
        "weight_inits_ = ['xavier_uniform','xavier_normal','kaiming_uniform','kaiming_normal']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#LOAD DATASETS\n",
        "#load fashionMNIST dataset \n",
        "train_set = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "test_set = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')\n",
        "\n",
        "\n",
        "\n",
        "#KFOLD\n",
        "num_folds = 5\n",
        "n_samples = len(train_set)\n",
        "indices = list(range(n_samples))\n",
        "fold_sizes = [(n_samples // num_folds) for _ in range(num_folds)]\n",
        "\n",
        "for fold, fold_size in enumerate(fold_sizes):\n",
        "    start = sum(fold_sizes[:fold])\n",
        "    stop = start + fold_size\n",
        "    train_indices = indices[:start] + indices[stop:]\n",
        "    val_indices = indices[start:stop]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "UwDRLGKiQOxg",
        "outputId": "fc7f9e2b-86fc-4e67-ac89-f2842a003536"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#SHOW DATA EXAMPLE\n",
        "plt.style.use('default')\n",
        "fig, ax = plt.subplots(2, 5, figsize=(8, 4))\n",
        "for i in range(10):\n",
        "  ax[i % 2, i % 5].imshow(train_set[i][0][0], cmap='gray', vmin=0, vmax=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CiUMKrULmWYQ"
      },
      "outputs": [],
      "source": [
        "#CREATE CUSTOM NEURAL NETWORK\n",
        "\n",
        "#A model with 3 fully connected hidden layers and a fully connected output layer\n",
        "class NN_FullyConnectedLayers(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN_FullyConnectedLayers, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.fc2 = nn.Linear(64 , 128)\n",
        "        self.fc3 = nn.Linear(128, 256)\n",
        "        self.fc4 = nn.Linear(256, 10)\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.nn.functional .relu(self.fc1(x))\n",
        "        x = torch.nn.functional .relu(self.fc2(x))\n",
        "        x = torch.nn.functional .relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "nn_fc = NN_FullyConnectedLayers()\n",
        "\n",
        "#A model with 3 convolutional hidden layers and a fully connected output layer\n",
        "class  NN_ConvLayers(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN_ConvLayers, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc = nn.Linear(128 * 3 * 3, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.nn.functional.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 3 * 3) \n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "nn_c = NN_ConvLayers()\n",
        "\n",
        "#A model with two fully connected hidden layers and one convolutional hidden layer\n",
        "class NN_TwoFullyConnectedLayersModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN_TwoFullyConnectedLayersModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, 64)\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pool(torch.nn.functional .relu(self.conv1(x)))\n",
        "        x = x.view(-1, 32 * 14 * 14)\n",
        "        x = torch.nn.functional .relu(self.fc1(x))\n",
        "        x = torch.nn.functional .relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "nn_twofc = NN_TwoFullyConnectedLayersModel()\n",
        "\n",
        "\n",
        "#A model with two convolutional hidden layers and one fully connected layer and a fully connected output layer\n",
        "class NN_TwoConvLayersModel(nn.Module):\n",
        "  #after test I intialised the weight intialisation to the optimal one which was the kaiming_uniform initialisation\n",
        "    def __init__(self, weight_init='kaiming_uniform'):\n",
        "        super(NN_TwoConvLayersModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "        if weight_init == 'xavier_uniform':\n",
        "            init.xavier_uniform_(self.conv1.weight)\n",
        "            init.xavier_uniform_(self.conv2.weight)\n",
        "            init.xavier_uniform_(self.fc1.weight)\n",
        "            init.xavier_uniform_(self.fc2.weight)\n",
        "        elif weight_init == 'xavier_normal':\n",
        "            init.xavier_normal_(self.conv1.weight)\n",
        "            init.xavier_normal_(self.conv2.weight)\n",
        "            init.xavier_normal_(self.fc1.weight)\n",
        "            init.xavier_normal_(self.fc2.weight)\n",
        "\n",
        "        elif weight_init == 'kaiming_uniform':\n",
        "            init.kaiming_uniform_(self.conv1.weight)\n",
        "            init.kaiming_uniform_(self.conv2.weight)\n",
        "            init.kaiming_uniform_(self.fc1.weight)\n",
        "            init.kaiming_uniform_(self.fc2.weight)\n",
        "        elif weight_init == 'kaiming_normal':\n",
        "            init.kaiming_normal_(self.conv1.weight)\n",
        "            init.kaiming_normal_(self.conv2.weight)\n",
        "            init.kaiming_normal_(self.fc1.weight)\n",
        "            init.kaiming_normal_(self.fc2.weight)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown weight initialization: {weight_init}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.conv1(x))\n",
        "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 14 * 14)\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "nn_twoc = NN_TwoConvLayersModel()\n",
        "\n",
        "#a dictionary of all the models for testing \n",
        "model_dict = {\n",
        "    'ALL Convolutional Layers': nn_c,\n",
        "    'All Layers Fully Connected' : nn_fc,\n",
        "    'Two Fully Connected Layers , One Convolutional' : nn_twofc,\n",
        "    'Two Convolutional Layers, One Fully Connected' : nn_twoc\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pEmaktNuoZz-"
      },
      "outputs": [],
      "source": [
        "def get_train_val_split(train_data, n_splits=5):\n",
        "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    return list(kfold.split(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yZ3h0l9Cjk9o"
      },
      "outputs": [],
      "source": [
        "def run_model_crossval(model, train_set, num_epochs=10, learning_rate=0.01, momentum=0.9, n_splits=5):\n",
        "    # Define the loss function and the optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer_SGD = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # set up k-fold cross-validation\n",
        "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    fold_accuracies = [] \n",
        "    fold_losses = []  \n",
        "\n",
        "    for fold, (train_indices, val_indices) in enumerate(kfold.split(train_set), start=1):\n",
        "        print(f\"Running fold {fold}...\")\n",
        "\n",
        "        # split the training into training and validation subsets \n",
        "        train_subset = torch.utils.data.Subset(train_set, train_indices)\n",
        "        val_subset = torch.utils.data.Subset(train_set, val_indices)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "        val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "        # set the model to training mode\n",
        "        model.train()\n",
        "        for epoch in notebook.tqdm(range(num_epochs), desc='Epochs'):\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(train_loader):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer_SGD.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                # compute loss\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer_SGD.step()\n",
        "\n",
        "                # add loss over the epoch\n",
        "                running_loss += loss.item()\n",
        "\n",
        "            # average loss \n",
        "            running_loss /= len(train_loader)\n",
        "            print(f\"Epoch: {epoch+1}, Loss: {running_loss:.4f}\")\n",
        "\n",
        "        # set model to evaluation mode\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in val_loader:\n",
        "                images, labels = data\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # compute accuracy for this fold and print\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Fold {fold} accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        # store accuracy and loss for this fold\n",
        "        fold_accuracies.append(accuracy)\n",
        "        fold_losses.append(running_loss)\n",
        "\n",
        "    # calculate tge average accuracy and loss over all folds\n",
        "    avg_accuracy = np.mean(fold_accuracies)\n",
        "    avg_loss = np.mean(fold_losses)\n",
        "\n",
        "    print(f\"Cross-Validation Accuracy: {avg_accuracy:.2f}%, Average Loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MZdUEMFW2Ga_"
      },
      "outputs": [],
      "source": [
        "def run_model(model,learning_rate = 0.01, num_epochs =10, momentum=0.9, n_splits=5):\n",
        "    # Define the loss function and the optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer_SGD = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer_SGD, step_size=30, gamma=0.1)\n",
        "    epplot = []\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #device_gpu = torch.device(\"gpu\")\n",
        "    model.to(device)\n",
        "    total_epochs = notebook.tqdm(range(num_epochs))\n",
        "\n",
        "\n",
        "  #TRAIN NEURAL NETWORK\n",
        "    #set model to train\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer_SGD.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            #print(f\"Output shape: {outputs.shape}\") \n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer_SGD.step()\n",
        "            #add to loss\n",
        "            running_loss += loss.item()\n",
        "            #display loss\n",
        "            total_epochs.set_description(\n",
        "                  'Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
        "                      epoch + 1, num_epochs, i + 1, len(train_loader), loss.item()))\n",
        "        #step learning rate schedular\n",
        "        #scheduler.step() \n",
        "        running_loss = running_loss / (i + 1)\n",
        "        #add to plot list\n",
        "        epplot.append(running_loss)\n",
        "        #display epoch and loss\n",
        "        print(f\"Epoch: {epoch+1}, Loss: {running_loss:.4f}\") \n",
        "\n",
        "\n",
        "  #TEST NEURAL NETWORK\n",
        "    #put model in eval mode\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy =  100 * correct / total\n",
        "    #display accuracy\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    return epplot\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use cross val on a model\n",
        "def run_crossval_model(model):\n",
        "  trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "  trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "  testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "  testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "  classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')\n",
        "\n",
        "  run_model_crossval(model,trainset)\n",
        "\n",
        "run_crossval_model(NN_TwoConvLayersModel())"
      ],
      "metadata": {
        "id": "pjWGTlUQET7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2Bfn39YQTBJ"
      },
      "outputs": [],
      "source": [
        "#TEST ALL MODELS\n",
        "def test_models(model_dict):\n",
        "  #loop through all models in the dictionary\n",
        "  for model_name, model in model_dict.items():\n",
        "    print(model_name)\n",
        "    #run the current model\n",
        "    plot = run_model(model)\n",
        "    #plot on graph\n",
        "    plt.plot(plot, label = str(model_name))\n",
        "\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Effect of Architecture on loss\")\n",
        "  plt.show()\n",
        "\n",
        "test_models(model_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgpC3EzzAcLR"
      },
      "outputs": [],
      "source": [
        "#TEST ALL LEARNING RATES\n",
        "def test_learning_rates(learning_rates):\n",
        "  #loop through learning rates\n",
        "  for i, lr in enumerate(learning_rates):\n",
        "      model_test = NN_TwoConvLayersModel()\n",
        "      #run model with given learning rate\n",
        "      plot = run_model(model_test, learning_rate = lr)\n",
        "      #plot on graph\n",
        "      plt.plot(plot, label = str(lr))\n",
        "      plt.xlabel(\"Epochs\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.legend()\n",
        "  \n",
        "  plt.title(\"Loss vs. Learning Rate for lr\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "test_learning_rates(learning_rates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G63cp8XDEWcP"
      },
      "outputs": [],
      "source": [
        "#TEST WEIGHT INITS\n",
        "def test_weight_inits(weight_inits_):\n",
        "  #loop through all the weight inits\n",
        "  for i, weight in enumerate(weight_inits_):\n",
        "    print(weight)\n",
        "    #apply the weight init to the model\n",
        "    model_test = NN_TwoConvLayersModel(weight_init = weight)\n",
        "    #run model\n",
        "    plot = run_model(model_test)\n",
        "    #plot graph\n",
        "    plt.plot(plot, label = str(weight))\n",
        "\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Effect of Weight Initialisations on Loss\")\n",
        "  plt.show()\n",
        "\n",
        "test_weight_inits(weight_inits_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dbYkq4G4EVN"
      },
      "outputs": [],
      "source": [
        "#TEST ALL TRANSFORMATIONS\n",
        "def test_augmentations(transformations):\n",
        "\n",
        "  for i, tf in enumerate(transformations):\n",
        "    #get names for transformations\n",
        "    string = \"\"\n",
        "    if i == 0:\n",
        "        string = \"Regular\"\n",
        "    elif i == 1:\n",
        "        string = \"Random Horizontal Flip\"\n",
        "    elif i == 2:\n",
        "        string = \"Color Jitter\"\n",
        "    elif i == 3:\n",
        "        string = \"Random Rotation\"\n",
        "\n",
        "    #redownload dataset with the chosen transformation applied\n",
        "    train_set = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=tf)\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    test_set = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=tf)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')\n",
        "    #run model\n",
        "    model_test = NN_TwoConvLayersModel()\n",
        "    #plot graph\n",
        "    plot = run_model(model_test)\n",
        "    plt.plot(plot, label = str(string))\n",
        "\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Effect of Transformations on Loss\")\n",
        "  plt.show()\n",
        " \n",
        "test_augmentations(transformations)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnCtYOoe4IMk"
      },
      "outputs": [],
      "source": [
        "#TEST ALL BATCH SIZES\n",
        "def test_batch_sizes(batch_sizes):\n",
        "  for bs in batch_sizes:\n",
        "    #redownload training set while changing the batch_size\n",
        "    train_set = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=bs, shuffle=True, num_workers=0)\n",
        "\n",
        "    test_set = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=bs, shuffle=False, num_workers=0)\n",
        "\n",
        "    classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')\n",
        "    #run the model\n",
        "    model_test = NN_TwoConvLayersModel()\n",
        "    #plot the graph\n",
        "    plot = run_model(model_test)\n",
        "    plt.plot(plot, label = str(bs))\n",
        "\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Effect of Batch Size on Loss\")\n",
        "  plt.show()\n",
        "\n",
        "test_batch_sizes(batch_sizes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_ResNet():\n",
        "   preprocess = transforms.Compose([\n",
        "      transforms.Resize(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # FashionMNIST is grayscale, convert to 3-channel\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  ])\n",
        "   return preprocess"
      ],
      "metadata": {
        "id": "6gxPN8Ml5KAA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neuron_activities(model,test_loader):\n",
        "  features = []\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in test_loader:\n",
        "      inputs = inputs.to('cuda')\n",
        "      outputs = model(inputs)\n",
        "      features.extend(outputs.cpu().numpy().reshape(outputs.shape[0], -1))\n",
        "\n",
        "  features = np.array(features)\n",
        "  return features\n"
      ],
      "metadata": {
        "id": "8JsmeM9b9Rbw"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "WSUXPGTgdMXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9864acec-c7d0-477e-fb1a-f9341b52bfb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet-18 Correlation Matrix Shape: (512, 512)\n",
            "============================================\n",
            "Your Model Correlation Matrix Shape: (10, 10)\n",
            "ResNet-18 Correlation Mean: 0.022130002433291416 Standard Deviation: 0.1640979494190549\n",
            "Your Model Correlation Mean: 0.08295415179842504 Standard Deviation: 0.4048674288609988\n"
          ]
        }
      ],
      "source": [
        "def compare_with_ResNet(model):\n",
        "  #preprocess ResNet dataset\n",
        "  preprocess =preprocess_ResNet()\n",
        "  test_set = FashionMNIST(root='./data', train=False, download=True, transform=preprocess)\n",
        "\n",
        "  # select 100 images from each class\n",
        "  indices = []\n",
        "  for i in range(10):\n",
        "      class_indices = (test_set.targets == i).nonzero(as_tuple=True)[0]\n",
        "      indices.extend(class_indices[:100].tolist())\n",
        "  subset_test_set = Subset(test_set, indices)\n",
        "\n",
        "  # create DataLoader\n",
        "  test_loader = DataLoader(subset_test_set, batch_size=10, shuffle=False)\n",
        "\n",
        "  # load pre-trained ResNet-18 model\n",
        "  resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "  # remove the last layer for feature extraction\n",
        "  resnet18 = torch.nn.Sequential(*(list(resnet18.children())[:-1]))\n",
        "\n",
        "  resnet18.eval()  \n",
        "  resnet18 = resnet18.to('cuda')  \n",
        "\n",
        "  # compute neuron activities\n",
        "  features = neuron_activities(resnet18,test_loader)\n",
        " \n",
        "\n",
        "  # compute correlation matrix\n",
        "  corr_matrix_resnet = np.corrcoef(features.T)\n",
        "  print(\"ResNet-18 Correlation Matrix Shape:\", corr_matrix_resnet.shape)\n",
        "  print(\"============================================\")\n",
        "\n",
        "  # modify the first layer of your model to accept 3-channel input\n",
        "  model.conv1 = torch.nn.Conv2d(3, model.conv1.out_channels, kernel_size=model.conv1.kernel_size, \n",
        "                                  stride=model.conv1.stride, padding=model.conv1.padding, \n",
        "                                  dilation=model.conv1.dilation, groups=model.conv1.groups, \n",
        "                                  bias=model.conv1.bias is not None)\n",
        "\n",
        "  model = model.to('cuda')\n",
        "  model.eval()\n",
        "\n",
        "  # compute neuron activities for my custom model\n",
        "  features_model = neuron_activities(model,test_loader)\n",
        " \n",
        "\n",
        "  # compute correlation matrix for my custom mode\n",
        "  corr_matrix_your_model = np.corrcoef(features_model.T)\n",
        "  print(\"Your Model Correlation Matrix Shape:\", corr_matrix_your_model.shape)\n",
        "\n",
        "  # compute the mean and standard deviation of the correlation matrices\n",
        "  mean_corr_resnet = np.mean(corr_matrix_resnet)\n",
        "  std_corr_resnet = np.std(corr_matrix_resnet)\n",
        "  mean_corr_your_model = np.mean(corr_matrix_your_model)\n",
        "  std_corr_your_model = np.std(corr_matrix_your_model)\n",
        "\n",
        "  print(\"ResNet-18 Correlation Mean:\", mean_corr_resnet, \"Standard Deviation:\", std_corr_resnet)\n",
        "  print(\"Your Model Correlation Mean:\", mean_corr_your_model, \"Standard Deviation:\", std_corr_your_model)\n",
        "\n",
        "\n",
        "compare_with_ResNet(NN_TwoConvLayersModel())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}